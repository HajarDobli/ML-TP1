{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb9b1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f5d3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Téléchargement des stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa553516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movie_review.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4502f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fold_id cv_tag  html_id  sent_id  \\\n",
      "0            0  cv000    29590        0   \n",
      "1            0  cv000    29590        1   \n",
      "2            0  cv000    29590        2   \n",
      "3            0  cv000    29590        3   \n",
      "4            0  cv000    29590        4   \n",
      "...        ...    ...      ...      ...   \n",
      "64715        9  cv999    14636       20   \n",
      "64716        9  cv999    14636       21   \n",
      "64717        9  cv999    14636       22   \n",
      "64718        9  cv999    14636       23   \n",
      "64719        9  cv999    14636       24   \n",
      "\n",
      "                                                    text  tag  \n",
      "0      films adapted from comic books have had plenty...  pos  \n",
      "1      for starters  it was created by alan moore  an...  pos  \n",
      "2      to say moore and campbell thoroughly researche...  pos  \n",
      "3      the book  or  graphic novel   if you will  is ...  pos  \n",
      "4      in other words  dont dismiss this film because...  pos  \n",
      "...                                                  ...  ...  \n",
      "64715  that lack of inspiration can be traced back to...  neg  \n",
      "64716  like too many of the skits on the current inca...  neg  \n",
      "64717  after watching one of the  roxbury  skits on s...  neg  \n",
      "64718         bump unsuspecting women  and    thats all   neg  \n",
      "64719  after watching anightattheroxbury  youll be le...  neg  \n",
      "\n",
      "[64720 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cleaning\n",
    "import re\n",
    "\n",
    "# Clean the 'text' column: removing punctuation and underscores\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(r'[^\\w\\s]|_', '', str(x)))\n",
    "\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b72161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters  it was created by alan moore  an...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book  or  graphic novel   if you will  is ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words  dont dismiss this film because...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>20</td>\n",
       "      <td>that lack of inspiration can be traced back to...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>21</td>\n",
       "      <td>like too many of the skits on the current inca...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>22</td>\n",
       "      <td>after watching one of the  roxbury  skits on s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>23</td>\n",
       "      <td>bump unsuspecting women  and    thats all</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>24</td>\n",
       "      <td>after watching anightattheroxbury  youll be le...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold_id cv_tag  html_id  sent_id  \\\n",
       "0            0  cv000    29590        0   \n",
       "1            0  cv000    29590        1   \n",
       "2            0  cv000    29590        2   \n",
       "3            0  cv000    29590        3   \n",
       "4            0  cv000    29590        4   \n",
       "...        ...    ...      ...      ...   \n",
       "64715        9  cv999    14636       20   \n",
       "64716        9  cv999    14636       21   \n",
       "64717        9  cv999    14636       22   \n",
       "64718        9  cv999    14636       23   \n",
       "64719        9  cv999    14636       24   \n",
       "\n",
       "                                                    text  tag  \n",
       "0      films adapted from comic books have had plenty...  pos  \n",
       "1      for starters  it was created by alan moore  an...  pos  \n",
       "2      to say moore and campbell thoroughly researche...  pos  \n",
       "3      the book  or  graphic novel   if you will  is ...  pos  \n",
       "4      in other words  dont dismiss this film because...  pos  \n",
       "...                                                  ...  ...  \n",
       "64715  that lack of inspiration can be traced back to...  neg  \n",
       "64716  like too many of the skits on the current inca...  neg  \n",
       "64717  after watching one of the  roxbury  skits on s...  neg  \n",
       "64718         bump unsuspecting women  and    thats all   neg  \n",
       "64719  after watching anightattheroxbury  youll be le...  neg  \n",
       "\n",
       "[64720 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"] = data[\"text\"].str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d04ce73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [films, adapted, from, comic, books, have, had...\n",
      "1        [for, starters, it, was, created, by, alan, mo...\n",
      "2        [to, say, moore, and, campbell, thoroughly, re...\n",
      "3        [the, book, or, graphic, novel, if, you, will,...\n",
      "4        [in, other, words, dont, dismiss, this, film, ...\n",
      "                               ...                        \n",
      "64715    [that, lack, of, inspiration, can, be, traced,...\n",
      "64716    [like, too, many, of, the, skits, on, the, cur...\n",
      "64717    [after, watching, one, of, the, roxbury, skits...\n",
      "64718         [bump, unsuspecting, women, and, thats, all]\n",
      "64719    [after, watching, anightattheroxbury, youll, b...\n",
      "Name: text, Length: 64720, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Tokenization: splitting the string into a list of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "#used a lambda expression :\n",
    "data['text'] = data['text'].apply(lambda x: word_tokenize(str(x)))\n",
    "\n",
    "print(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41707f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [films, adapted, comic, books, plenty, success...\n",
      "1        [starters, created, alan, moore, eddie, campbe...\n",
      "2        [say, moore, campbell, thoroughly, researched,...\n",
      "3        [book, graphic, novel, 500, pages, long, inclu...\n",
      "4                     [words, dont, dismiss, film, source]\n",
      "                               ...                        \n",
      "64715    [lack, inspiration, traced, back, insipid, cha...\n",
      "64716    [like, many, skits, current, incarnation, satu...\n",
      "64717    [watching, one, roxbury, skits, snl, come, awa...\n",
      "64718                   [bump, unsuspecting, women, thats]\n",
      "64719    [watching, anightattheroxbury, youll, left, ex...\n",
      "Name: text, Length: 64720, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Removing stop_words : Removing not meaningful words.\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the English stop words\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "data['text'] = data['text'].apply(lambda sentence_tokens: [word for word in sentence_tokens if word not in stop_words ])\n",
    "\n",
    "print(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fd82553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec :\n",
    "import gensim\n",
    "#affecting to each word of my dataSet a vector (size=100)\n",
    "\n",
    "# training my Word2Vec model\n",
    "model =gensim.models.Word2Vec(sentences=data['text'], vector_size=100, window=5, min_count=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3955f457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858998"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can use the model to calculate the similariy between two words\n",
    "model.wv.similarity(w1=\"medium\", w2=\"mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e9cb2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11371017,  0.23658514,  0.11907139,  0.02680179,  0.07633563,\n",
       "       -0.37607774,  0.07109237,  0.35787138, -0.1033361 , -0.14891931,\n",
       "       -0.04476611, -0.25191915, -0.10972837,  0.08973026,  0.1589317 ,\n",
       "       -0.1829076 ,  0.03247021, -0.23724377,  0.01456126, -0.37496755,\n",
       "        0.11318682,  0.1635985 ,  0.1546356 , -0.10595743, -0.05694155,\n",
       "        0.00347008, -0.16999654,  0.02026771, -0.31001177,  0.02527394,\n",
       "        0.13495469, -0.05862148,  0.03337866, -0.10819975,  0.03973536,\n",
       "        0.14785743, -0.03083589, -0.13162921, -0.04839679, -0.34127417,\n",
       "       -0.00756371, -0.22823255, -0.11172352, -0.0401496 ,  0.11674498,\n",
       "       -0.01388765, -0.1660169 ,  0.01049154,  0.08583508,  0.23191142,\n",
       "        0.06678457, -0.15054525, -0.08441942, -0.03786461, -0.07992531,\n",
       "        0.16246246,  0.1449552 ,  0.04094772, -0.19906922,  0.10632405,\n",
       "        0.050855  ,  0.04764174, -0.17746527,  0.06467976, -0.12429555,\n",
       "        0.12130193,  0.01522932,  0.07646833, -0.20834838,  0.22857723,\n",
       "       -0.10900388,  0.09166092,  0.26357302, -0.23273961,  0.13400656,\n",
       "        0.09009469,  0.03737398, -0.05485046, -0.10439532,  0.01812976,\n",
       "       -0.07198976, -0.03200844, -0.19998893,  0.24801378, -0.03098794,\n",
       "       -0.01967912, -0.09430832,  0.24753588,  0.23440836,  0.09109706,\n",
       "        0.1628176 ,  0.04001089,  0.17333257,  0.09534851,  0.26248032,\n",
       "        0.12239348,  0.12465896, -0.21509086,  0.07602666,  0.04694691],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example the vector representing the word films is : \n",
    "word_vector = model.wv['medium']\n",
    "word_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b293e2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.38457566, 0.6921082, 0.26475358, 0.0576685...\n",
       "1        [-0.2358836, 0.39502096, 0.2510185, 0.07911752...\n",
       "2        [-0.42818612, 0.75692177, 0.2970959, 5.729935e...\n",
       "3        [-0.24574526, 0.443748, 0.24293397, 0.08014274...\n",
       "4        [-0.47378436, 0.8001005, 0.2753085, 0.12274642...\n",
       "                               ...                        \n",
       "64715    [-0.2291087, 0.5947063, 0.27173412, -0.0759562...\n",
       "64716    [-0.3075606, 0.5889383, 0.22496998, -0.0131542...\n",
       "64717    [-0.42597672, 0.70531964, 0.35018417, 0.050108...\n",
       "64718    [-0.29888692, 0.58587724, 0.26110876, 0.064377...\n",
       "64719    [-0.55378985, 0.6722865, 0.33155996, 0.2461058...\n",
       "Name: review_vector, Length: 64720, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# pour chaque mot du vocabulaire , on va récuperer le vecteur correspondants et on va  stocké l'ensemble de ces vecteurs dans un tab\n",
    "def get_word_embeddings(review, model):\n",
    "    word_embeddings = []\n",
    "    for word in review:\n",
    "        #Vérifier Si le mot est présent dans le vocabulaire du modèle :c'est-à-dire qu'il a été vu lors de l'entraînement du modèle\n",
    "        if word in model.wv.key_to_index:\n",
    "            word_embeddings.append(model.wv[word])\n",
    "    return word_embeddings\n",
    "\n",
    "# Fonction pour obtenir le vecteur moyen d'une critique\n",
    "def get_review_vector(review, model):\n",
    "    word_embeddings = get_word_embeddings(review, model)\n",
    "    if word_embeddings:\n",
    "        return np.mean(word_embeddings, axis=0)\n",
    "    else:\n",
    "        # Si la critique ne contient pas de mots dans le vocabulaire du modèle, retourner un vecteur nul\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "\n",
    "data['review_vector'] = data['text'].apply(lambda x: get_review_vector(x, model))\n",
    "data['review_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0991cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.570920889987639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données : partie training et testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review_vector'].values.tolist(), data['tag'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir les listes de vecteurs en matrices NumPy : pour que les features et targets aient des formes compatibles\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "# Créer et entraîner le modèle de régression logistique\n",
    "model1 = linear_model.LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "accuracy = model1.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "613b715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions : ['pos' 'pos' 'pos' ... 'neg' 'neg' 'pos']\n"
     ]
    }
   ],
   "source": [
    "#prediction :(sachant que le .score l'effectue implicitement)\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Prédictions :\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e9ea6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.570920889987639\n",
      "Precision : 0.5731664424140476\n",
      "Recall : 0.570920889987639\n",
      "F1-score : 0.5645694655052206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculer les prédictions sur l'ensemble de test\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# Calculer les métriques d'évaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Accuracy :\", accuracy)\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"F1-score :\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd6fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3a40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed407aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012d8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7c463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
